{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNL2G5PHMoclCYWr7gFvPhn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "67fa77f8ab0d4515bb2fd383a863abc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80428c5e5dba4bb7bd55a13b7626fc9f",
              "IPY_MODEL_3a0d181614964d64919057e1c2f689eb",
              "IPY_MODEL_3a87b978d2e54a2eb60c5f4421988948"
            ],
            "layout": "IPY_MODEL_b51f49cc1bdb4073a3d555771ebf92e4"
          }
        },
        "80428c5e5dba4bb7bd55a13b7626fc9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eceda5e44e3844ff8ea053d764757c4a",
            "placeholder": "​",
            "style": "IPY_MODEL_f41ec32729e445cabe13f521ff304ea7",
            "value": "100%"
          }
        },
        "3a0d181614964d64919057e1c2f689eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_750e9a7140b24404af5b5b62c12846f2",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e8ddcf9322b456d822304bf57fa6d1b",
            "value": 170498071
          }
        },
        "3a87b978d2e54a2eb60c5f4421988948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8221c0745e04dcdbf820439196c986c",
            "placeholder": "​",
            "style": "IPY_MODEL_00062d22eaaa4ce189801b3e05e11d91",
            "value": " 170498071/170498071 [00:03&lt;00:00, 65172881.26it/s]"
          }
        },
        "b51f49cc1bdb4073a3d555771ebf92e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eceda5e44e3844ff8ea053d764757c4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f41ec32729e445cabe13f521ff304ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "750e9a7140b24404af5b5b62c12846f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e8ddcf9322b456d822304bf57fa6d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8221c0745e04dcdbf820439196c986c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00062d22eaaa4ce189801b3e05e11d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srujanponnur/Balanced_Pruning/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hw4vGTtoggsX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "import copy\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torchvision.utils as vutils\n",
        "import seaborn as sns\n",
        "import torch.nn.init as init\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPosEXeDoe_W",
        "outputId": "41716f26-8565-46a7-b78e-6b8f884d2537"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "mElqcpvKgo2Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet5(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16*5*5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vXn03BJRiW7-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weight_init(m):\n",
        "    '''\n",
        "    Usage:\n",
        "        model = Model()\n",
        "        model.apply(weight_init)\n",
        "    '''\n",
        "    if isinstance(m, nn.Conv1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.Conv2d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.Conv3d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose2d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose3d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.BatchNorm1d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm3d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.LSTM):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.LSTMCell):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.GRU):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.GRUCell):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)"
      ],
      "metadata": {
        "id": "VC0LBMTvkh8g"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "checks for an existence of a directory and creates one if it doesnt exist"
      ],
      "metadata": {
        "id": "6JOwHTYgl-2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkdir(directory):\n",
        "  if not os.path.exists(directory):\n",
        "    os.makedirs(directory)"
      ],
      "metadata": {
        "id": "wNYkOLvDl71k"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet18():\n",
        "    return ResNet(BasicBlock, [2,2,2,2])"
      ],
      "metadata": {
        "id": "jpUyOZkRgso-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to make an empty mask of the same size as the model"
      ],
      "metadata": {
        "id": "wilX9CwFyeva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_mask(model):\n",
        "    global step\n",
        "    global mask\n",
        "    step = 0\n",
        "    for name, param in model.named_parameters(): \n",
        "        if 'weight' in name:\n",
        "            step = step + 1\n",
        "    mask = [None]* step \n",
        "    step = 0\n",
        "    for name, param in model.named_parameters(): \n",
        "        if 'weight' in name:\n",
        "            tensor = param.data.cpu().numpy()\n",
        "            mask[step] = np.ones_like(tensor)\n",
        "            step = step + 1\n",
        "    step = 0"
      ],
      "metadata": {
        "id": "r9mstSG9yd_o"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prints the non zeros of each layer in the model"
      ],
      "metadata": {
        "id": "nP8wwDp-5LpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_nonzeros(model):\n",
        "    nonzero = total = 0\n",
        "    for name, p in model.named_parameters():\n",
        "        tensor = p.data.cpu().numpy()\n",
        "        nz_count = np.count_nonzero(tensor)\n",
        "        total_params = np.prod(tensor.shape)\n",
        "        nonzero += nz_count\n",
        "        total += total_params\n",
        "        print(f'{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | total_pruned = {total_params - nz_count :7} | shape = {tensor.shape}')\n",
        "    print(f'alive: {nonzero}, pruned : {total - nonzero}, total: {total}, Compression rate : {total/nonzero:10.2f}x  ({100 * (total-nonzero) / total:6.2f}% pruned)')\n",
        "    return (round((nonzero/total)*100,1))"
      ],
      "metadata": {
        "id": "1vLhX-R54q-4"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original Initialization"
      ],
      "metadata": {
        "id": "iMZDkYmy28UL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def original_initialization(mask_temp, initial_state_dict):\n",
        "    global model\n",
        "    \n",
        "    step = 0\n",
        "    for name, param in model.named_parameters(): \n",
        "        if \"weight\" in name: \n",
        "            weight_dev = param.device\n",
        "            param.data = torch.from_numpy(mask_temp[step] * initial_state_dict[name].cpu().numpy()).to(weight_dev)\n",
        "            step = step + 1\n",
        "        if \"bias\" in name:\n",
        "            param.data = initial_state_dict[name]\n",
        "    step = 0"
      ],
      "metadata": {
        "id": "zA6GTLeg27j8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Prune by Percentile module"
      ],
      "metadata": {
        "id": "I7ZmELlqyq32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_by_percentile(percent, resample=False, reinit=False,**kwargs):\n",
        "        global step\n",
        "        global mask\n",
        "        global model\n",
        "\n",
        "        # Calculate percentile value\n",
        "        step = 0\n",
        "        for name, param in model.named_parameters():\n",
        "\n",
        "            # We do not prune bias term\n",
        "            if 'weight' in name:\n",
        "                tensor = param.data.cpu().numpy()\n",
        "                alive = tensor[np.nonzero(tensor)] # flattened array of nonzero values\n",
        "                percentile_value = np.percentile(abs(alive), percent)\n",
        "\n",
        "                # Convert Tensors to numpy and calculate\n",
        "                weight_dev = param.device\n",
        "                new_mask = np.where(abs(tensor) < percentile_value, 0, mask[step])\n",
        "                \n",
        "                # Apply new weight and mask\n",
        "                param.data = torch.from_numpy(tensor * new_mask).to(weight_dev)\n",
        "                mask[step] = new_mask\n",
        "                step += 1\n",
        "        step = 0"
      ],
      "metadata": {
        "id": "XBVTfWl-ymSM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for training"
      ],
      "metadata": {
        "id": "lTg31xjy6H3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, criterion):\n",
        "    EPS = 1e-6\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.train()\n",
        "    for batch_idx, (imgs, targets) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        #imgs, targets = next(train_loader)\n",
        "        imgs, targets = imgs.to(device), targets.to(device)\n",
        "        output = model(imgs)\n",
        "        train_loss = criterion(output, targets)\n",
        "        train_loss.backward()\n",
        "\n",
        "        # Freezing Pruned weights by making their gradients Zero\n",
        "        for name, p in model.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                tensor = p.data.cpu().numpy()\n",
        "                grad_tensor = p.grad.data.cpu().numpy()\n",
        "                grad_tensor = np.where(tensor < EPS, 0, grad_tensor)\n",
        "                p.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
        "        optimizer.step()\n",
        "    return train_loss.item()"
      ],
      "metadata": {
        "id": "FkfFOTFy6Eul"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for testing"
      ],
      "metadata": {
        "id": "zS7jHm3u6M16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader, criterion):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "5kC1yZCE6LOh"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
        "traindataset = datasets.CIFAR10('../data', train=True, download=True,transform=transform)\n",
        "testdataset = datasets.CIFAR10('../data', train=False, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "67fa77f8ab0d4515bb2fd383a863abc1",
            "80428c5e5dba4bb7bd55a13b7626fc9f",
            "3a0d181614964d64919057e1c2f689eb",
            "3a87b978d2e54a2eb60c5f4421988948",
            "b51f49cc1bdb4073a3d555771ebf92e4",
            "eceda5e44e3844ff8ea053d764757c4a",
            "f41ec32729e445cabe13f521ff304ea7",
            "750e9a7140b24404af5b5b62c12846f2",
            "7e8ddcf9322b456d822304bf57fa6d1b",
            "e8221c0745e04dcdbf820439196c986c",
            "00062d22eaaa4ce189801b3e05e11d91"
          ]
        },
        "id": "hgu__nHNgzFa",
        "outputId": "bf5e004a-b2e5-40dd-9dc1-929adbffaa2d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67fa77f8ab0d4515bb2fd383a863abc1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/cifar-10-python.tar.gz to ../data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(traindataset, batch_size=60, shuffle=True, num_workers=0,drop_last=False)\n",
        "    #train_loader = cycle(train_loader)\n",
        "test_loader = torch.utils.data.DataLoader(testdataset, batch_size=60, shuffle=False, num_workers=0,drop_last=True)"
      ],
      "metadata": {
        "id": "9Aat9dCvh7Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "A8mMrU8Gj3MF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = resnet18().to(device)   "
      ],
      "metadata": {
        "id": "FNSIHyEgj-Va"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model = LeNet5().to(device)"
      ],
      "metadata": {
        "id": "TPjYWQkGko0F"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change this variable to alter the model"
      ],
      "metadata": {
        "id": "sqMgUa1g6goJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = lenet_model"
      ],
      "metadata": {
        "id": "VuXmojgc6dke"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.apply(weight_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKj2pz7nk3ry",
        "outputId": "8e108404-0426-4ab5-d3eb-f7959571dada"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet5(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_state_dict = copy.deepcopy(model.state_dict()) # check what model points to!"
      ],
      "metadata": {
        "id": "pngRV0gZk-uI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the directories in google drive"
      ],
      "metadata": {
        "id": "JlarP-8Xp-pP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkdir(f'/content/drive/MyDrive/saves/lenet/cifar10/')      # change the directory depending on model"
      ],
      "metadata": {
        "id": "ho71lPz-o9te"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, f\"/content/drive/MyDrive/saves/lenet/cifar10/initial_state_dict_lt.pth.tar\")"
      ],
      "metadata": {
        "id": "_bnwSBmQlxdP"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_mask(model)"
      ],
      "metadata": {
        "id": "4OMmR5o2oLOA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss() # Default was F.nll_loss"
      ],
      "metadata": {
        "id": "vCBMtKQFyxnx"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name, param.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OKDAp38y6KI",
        "outputId": "67c84863-57ff-4266-84a7-3c96e8f3deb5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight torch.Size([6, 3, 5, 5])\n",
            "conv1.bias torch.Size([6])\n",
            "conv2.weight torch.Size([16, 6, 5, 5])\n",
            "conv2.bias torch.Size([16])\n",
            "fc1.weight torch.Size([120, 400])\n",
            "fc1.bias torch.Size([120])\n",
            "fc2.weight torch.Size([84, 120])\n",
            "fc2.bias torch.Size([84])\n",
            "fc3.weight torch.Size([10, 84])\n",
            "fc3.bias torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters Needed (Change if needed)"
      ],
      "metadata": {
        "id": "oq5hewQ-2l4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bestacc = 0.0\n",
        "best_accuracy = 0\n",
        "ITERATION = 35 # number of cycles of pruning that should be done.\n",
        "comp = np.zeros(ITERATION,float)\n",
        "bestacc = np.zeros(ITERATION,float)\n",
        "step = 0\n",
        "end_iter = 100 # Number of Epochs\n",
        "all_loss = np.zeros(end_iter, float)\n",
        "all_accuracy = np.zeros(end_iter, float)\n",
        "prune_percent = 10 # 10 percent pruning rate\n",
        "reinit = False # this is false because we are using lottery ticket\n",
        "resample = False # resample\n",
        "lr = 1.2e-3\n",
        "ITE = 1 # First time running the whole process\n",
        "valid_freq = 1 # frequency of validation\n",
        "print_freq = 1 # frequency for printing the loss and accuracy (prints every iteration)"
      ],
      "metadata": {
        "id": "y1xjWq47y_7R"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ite in range(0, ITERATION):\n",
        "  if not _ite == 0:\n",
        "      prune_by_percentile(prune_percent, resample=resample, reinit=reinit)\n",
        "      original_initialization(mask, initial_state_dict)\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "  print(f\"\\n--- Pruning Level [{ITE}:{_ite}/{ITERATION}]: ---\")\n",
        "  comp[_ite] = print_nonzeros(model)\n",
        "  pbar = tqdm(range(end_iter))\n",
        "  for iter_ in pbar:\n",
        "    # Frequency for Testing\n",
        "    if iter_ % valid_freq == 0:\n",
        "        accuracy = test(model, test_loader, criterion)\n",
        "        # Save Weights if accuracy is greater than best accuracy\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            checkdir(f\"/content/drive/MyDrive/saves/lenet/cifar10/\") # change the path depending on model\n",
        "            torch.save(model,f\"/content/drive/MyDrive/saves/lenet/cifar10/{_ite}_model_lt.pth.tar\")\n",
        "\n",
        "    # Training\n",
        "    loss = train(model, train_loader, optimizer, criterion)\n",
        "    all_loss[iter_] = loss # save loss for that iteration\n",
        "    all_accuracy[iter_] = accuracy # save accuracy for that iteration\n",
        "    \n",
        "    # Frequency for Printing Accuracy and Loss\n",
        "    if iter_ % print_freq == 0:\n",
        "        pbar.set_description(\n",
        "            f'Train Epoch: {iter_}/{end_iter} Loss: {loss:.6f} Accuracy: {accuracy:.2f}% Best Accuracy: {best_accuracy:.2f}%')\n",
        "  bestacc[_ite] = best_accuracy\n",
        "  plt.plot(np.arange(1,(end_iter)+1), 100*(all_loss - np.min(all_loss))/np.ptp(all_loss).astype(float), c=\"blue\", label=\"Loss\") \n",
        "  plt.plot(np.arange(1,(end_iter)+1), all_accuracy, c=\"red\", label=\"Accuracy\") \n",
        "  plt.title(f\"Loss Vs Accuracy Vs Iterations (CIFAR10,LENET)\") \n",
        "  plt.xlabel(\"Iterations\") \n",
        "  plt.ylabel(\"Loss and Accuracy\") \n",
        "  plt.legend() \n",
        "  plt.grid(color=\"gray\") \n",
        "  checkdir(f\"{os.getcwd()}/plots/lt/lenet/cifar10/\")\n",
        "  plt.savefig(f\"{os.getcwd()}/plots/lt/lenet/cifar10/lt_LossVsAccuracy_{comp1}.png\", dpi=1200) \n",
        "  plt.close()\n",
        "\n",
        "\n",
        "\n",
        "  best_accuracy = 0   # resetting the variables for next iteration\n",
        "  all_loss = np.zeros(args.end_iter,float)\n",
        "  all_accuracy = np.zeros(args.end_iter,float)\n"
      ],
      "metadata": {
        "id": "fn5tJMYV10Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZR8ogFAd8Uiv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}